# -*- coding: utf-8 -*-
"""Welcome To Colab

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/notebooks/welcome.ipynb
"""

!pip install langchain_community langchainhub chromadb langchain langchain-openai

from google.colab import userdata
import os
os.environ['OPENAI_API_KEY'] = userdata.get("openai_RAG_api")

from langchain_community.document_loaders import WebBaseLoader
loader = WebBaseLoader(web_paths=["https://www.educosys.com/course/genai"])

docs = loader.load()
print(docs)

from langchain.text_splitter import RecursiveCharacterTextSplitter
text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
splits = text_splitter.split_documents(docs)
print(splits)

print(splits[0])
print(splits[1])

print(len(splits))

!pip install sentence-transformers

from langchain.embeddings.openai import OpenAIEmbeddings
from langchain.vectorstores import Chroma
vectorstore = Chroma.from_documents(splits, embedding=OpenAIEmbeddings(), persist_directory="./chroma_openai")

print(f"Original docs: {len(docs)}")
print(f"Chunks created: {len(splits)}")
print(f"Chroma stored: {vectorstore._collection.count()}")

print(vectorstore._collection.get())

print("\nCollection 1 - ",vectorstore._collection.get(ids=['64308f81-e028-4e96-a608-87d09dd47423'], include = ["embeddings","documents"]))

retriever = vectorstore.as_retriever()

from langchain import hub
prompt = hub.pull("rlm/rag-prompt")

from langchain_openai import ChatOpenAI
llm = ChatOpenAI()

from langchain_core.runnables import RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser

def format_docs(docs):
  return "\n".join(doc.page_content for doc in docs)

rag_chain = ({"context" : retriever | format_docs, "question" : RunnablePassthrough()}
             | prompt
             | llm
             | StrOutputParser()
             )

rag_chain.invoke("Are the recordings of the course available? and for how long?")